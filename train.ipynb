{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6d5797-3980-4590-a9f5-08d1a1c3c858",
   "metadata": {},
   "source": [
    "## Loading librarires and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72f98ac-ec4d-4560-a755-959a4312c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/miniconda3/envs/cuda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import argparse\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa823451-8ef3-4267-8207-abed95e01864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca68adf-5841-4bd8-87e5-617ab01828fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './dataset/'\n",
    "df = pd.read_csv(data_dir+'processed_train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40040166-5f8f-47db-8584-3909ef11bc27",
   "metadata": {},
   "source": [
    "* use 2000 samples to make sure my code run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa674466-b18d-47fc-8e72-addc9b47f93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How surprising \\n\\nHow surprising that the art...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sounds like perpetual motion to me - the price...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your claim that the article supports your cita...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cholas and Vijayanagar empires are worth the m...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi, what do you know about the possible neande...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text              labels\n",
       "0  How surprising \\n\\nHow surprising that the art...  [0, 0, 0, 0, 0, 0]\n",
       "1  Sounds like perpetual motion to me - the price...  [0, 0, 0, 0, 0, 0]\n",
       "2  Your claim that the article supports your cita...  [0, 0, 0, 0, 0, 0]\n",
       "3  Cholas and Vijayanagar empires are worth the m...  [0, 0, 0, 0, 0, 0]\n",
       "4  hi, what do you know about the possible neande...  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = df.sample(2000).reset_index(drop=True)\n",
    "dfs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1fad3b-b68b-4a7a-b7ee-00b5a81d4bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    object\n",
       "labels          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebdd9465-04fe-434d-8210-f9c9b49e2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 0, 0, 0, 0, 0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['labels'][0] \n",
    "# need to care about this\n",
    "# i need to use `ast.literal_eval` to convert to list below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a7ecb-030c-471a-983b-c77f9e0fe8cb",
   "metadata": {},
   "source": [
    "Split into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa2a462-4f99-41f2-a192-b1c6eb68a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dfs.sample(frac=0.8, random_state=42)\n",
    "val_df = dfs.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2507b-99c5-4d25-a9d2-ff6a87092298",
   "metadata": {},
   "source": [
    "## Creating Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abd679-a150-4530-97e6-642bf7c28cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d40ac05-b312-4956-888b-a3a45c1b7e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer: transformers.BertTokenizer, max_len = 128):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.text = self.df.comment_text.values\n",
    "        self.label = self.df.labels.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        input = self.tokenizer.encode_plus(\n",
    "            text = text,\n",
    "            text_pair = None,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length = self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # import pdb; pdb.set_trace()\n",
    "        return {\n",
    "            'input_ids' : input.input_ids.squeeze(), ## MUST SQUEEZE\n",
    "            'attention_mask' : input.attention_mask.squeeze(), \n",
    "            'label' : torch.tensor(ast.literal_eval(self.label[idx]), dtype = torch.float)\n",
    "        }\n",
    "        # return {\n",
    "        #     'input_ids' : input.input_ids,\n",
    "        #     'attention_mask' : input.attention_mask\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11bfd869-adfc-4efe-9a5d-f652cbdb755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./bert')\n",
    "train = MyDataset(train_df, tokenizer, 200)\n",
    "val = MyDataset(val_df, tokenizer, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f2c511-a37a-424e-8cef-482c6c238b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfbe5c-1594-4560-98c9-e0deddb71f5c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d72728e8-c7f3-4ace-bd7e-d397e195c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049348d3-9a4c-4c82-aac5-183947b6de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBert(nn.Module):\n",
    "    def __init__(self, model_path = None, num_labels = 6):\n",
    "        super().__init__()\n",
    "        if model_path == None:\n",
    "            self.bert = AutoModel.from_pretrained('bert-based-uncase')\n",
    "        else:\n",
    "            self.bert = AutoModel.from_pretrained(model_path)\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.lin = nn.Linear(768, num_labels)\n",
    "    def forward(self, ids, mask):\n",
    "        pooler = self.bert(ids, mask)[-1] # pooler \n",
    "        # import pdb; pdb.set_trace()\n",
    "        pooler = self.drop_out(pooler)\n",
    "        return self.lin(pooler)\n",
    "model = MyBert(model_path='./bert').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef9b12d-0b2c-45dc-a240-5ef182b64a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=3e-5)\n",
    "loss_fn = F.binary_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bd0d2-2d75-49cf-9deb-4dd50e59d549",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "824bb90f-94b3-4c65-9557-b30bfb5a2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79c3aa1d-7666-46ae-9c3f-3b080e4b6bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ...: 100%|█| 200/200 [00:36<00:00,  5.50it/s, epoch=0, loss=tensor(0.04\n",
      "Training ...: 100%|█| 200/200 [00:37<00:00,  5.37it/s, epoch=1, loss=tensor(0.03\n",
      "Training ...: 100%|█| 200/200 [00:36<00:00,  5.42it/s, epoch=2, loss=tensor(0.02\n",
      "Training ...: 100%|█| 200/200 [00:36<00:00,  5.42it/s, epoch=3, loss=tensor(0.02\n",
      "Training ...: 100%|█| 200/200 [00:37<00:00,  5.39it/s, epoch=4, loss=tensor(0.01\n"
     ]
    }
   ],
   "source": [
    "def train(epochs = 1):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        tk0 = tqdm(train_dataloader, desc = 'Training ...')\n",
    "        losses = AverageMeter()\n",
    "        for i, batch in enumerate(tk0):\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            label = batch['label'].to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            output = model(ids, mask)\n",
    "            loss = loss_fn(output, label)\n",
    "            losses.update(loss, ids.shape[0])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            tk0.set_postfix(epoch = epoch, loss = losses.avg)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # break\n",
    "train(5)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e008870-854d-41a1-ad2f-983330f85527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_18134/1787273927.py\u001b[0m(16)\u001b[0;36mtest\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     14 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 16 \u001b[0;31m            \u001b[0mall_test_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mprobas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  probas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8960e-03, 9.9010e-04, 1.0140e-03, 1.0224e-03, 9.2756e-04, 1.4257e-03],\n",
      "        [9.8673e-01, 1.4279e-01, 8.5408e-01, 2.7308e-02, 9.5657e-01, 7.6640e-02],\n",
      "        [1.8749e-03, 9.9681e-04, 1.0238e-03, 1.0639e-03, 9.1174e-04, 1.4644e-03],\n",
      "        [2.0996e-03, 1.0024e-03, 1.0946e-03, 9.7992e-04, 9.8670e-04, 1.4091e-03],\n",
      "        [1.8507e-03, 1.0170e-03, 1.0260e-03, 1.0109e-03, 9.2857e-04, 1.4463e-03],\n",
      "        [2.2345e-03, 9.9958e-04, 1.0309e-03, 1.0249e-03, 9.8413e-04, 1.4357e-03],\n",
      "        [1.8208e-03, 1.0390e-03, 1.0214e-03, 1.0299e-03, 9.7679e-04, 1.4476e-03],\n",
      "        [1.8394e-03, 1.0317e-03, 1.0269e-03, 9.9866e-04, 9.6371e-04, 1.4379e-03]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  probas.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 6])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  probas[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0019, 0.0010, 0.0010, 0.0010, 0.0009, 0.0014], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "all_test_pred = []\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "    \n",
    "        for _, data in tqdm(enumerate(val_dataloader, 0)):\n",
    "\n",
    "            ids = data['input_ids'].to(DEVICE)\n",
    "            mask = data['attention_mask'].to(DEVICE)\n",
    "            outputs = model(ids, mask)\n",
    "            probas = torch.sigmoid(outputs)\n",
    "\n",
    "            import pdb; pdb.set_trace()\n",
    "            all_test_pred.append(probas)\n",
    "            \n",
    "    return probas\n",
    "probas = test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
