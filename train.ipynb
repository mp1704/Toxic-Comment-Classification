{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6d5797-3980-4590-a9f5-08d1a1c3c858",
   "metadata": {},
   "source": [
    "## Loading librarires and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f72f98ac-ec4d-4560-a755-959a4312c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import argparse\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa823451-8ef3-4267-8207-abed95e01864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca68adf-5841-4bd8-87e5-617ab01828fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './dataset/'\n",
    "df = pd.read_csv(data_dir+'processed_train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40040166-5f8f-47db-8584-3909ef11bc27",
   "metadata": {},
   "source": [
    "* use a part of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa674466-b18d-47fc-8e72-addc9b47f93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Personal opinion: That message above was very ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calling someone a consistent hypocrite is a pe...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What the FUCK? \\n\\nHow exactly am I engaged in...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Added the part of Harivamsa Purana \\n\\nI added...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it the same notability criteria for attaini...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text              labels\n",
       "0  Personal opinion: That message above was very ...  [0, 0, 0, 0, 0, 0]\n",
       "1  Calling someone a consistent hypocrite is a pe...  [0, 0, 0, 0, 0, 0]\n",
       "2  What the FUCK? \\n\\nHow exactly am I engaged in...  [1, 0, 1, 0, 1, 0]\n",
       "3  Added the part of Harivamsa Purana \\n\\nI added...  [0, 0, 0, 0, 0, 0]\n",
       "4  Is it the same notability criteria for attaini...  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = df.sample(5000).reset_index(drop=True)\n",
    "dfs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f1fad3b-b68b-4a7a-b7ee-00b5a81d4bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    object\n",
       "labels          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebdd9465-04fe-434d-8210-f9c9b49e2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 0, 0, 0, 0, 0]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['labels'][0] \n",
    "# need to care about this\n",
    "# i need to use `ast.literal_eval` to convert to list below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a7ecb-030c-471a-983b-c77f9e0fe8cb",
   "metadata": {},
   "source": [
    "Split into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aa2a462-4f99-41f2-a192-b1c6eb68a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dfs.sample(frac=0.8, random_state=42)\n",
    "val_df = dfs.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2507b-99c5-4d25-a9d2-ff6a87092298",
   "metadata": {},
   "source": [
    "## Creating Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abd679-a150-4530-97e6-642bf7c28cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d40ac05-b312-4956-888b-a3a45c1b7e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer: transformers.BertTokenizer, max_len = 128):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.text = self.df.comment_text.values\n",
    "        self.label = self.df.labels.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        input = self.tokenizer.encode_plus(\n",
    "            text = text,\n",
    "            text_pair = None,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length = self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # import pdb; pdb.set_trace()\n",
    "        return {\n",
    "            'input_ids' : input.input_ids.squeeze(), ## MUST SQUEEZE\n",
    "            'attention_mask' : input.attention_mask.squeeze(), \n",
    "            'label' : torch.tensor(ast.literal_eval(self.label[idx]), dtype = torch.float)\n",
    "        }\n",
    "        # return {\n",
    "        #     'input_ids' : input.input_ids,\n",
    "        #     'attention_mask' : input.attention_mask\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11bfd869-adfc-4efe-9a5d-f652cbdb755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./bert')\n",
    "train = MyDataset(train_df, tokenizer, 200)\n",
    "val = MyDataset(val_df, tokenizer, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24f2c511-a37a-424e-8cef-482c6c238b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfbe5c-1594-4560-98c9-e0deddb71f5c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d72728e8-c7f3-4ace-bd7e-d397e195c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6321d890-6792-4075-8f9d-2f1488a09061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "049348d3-9a4c-4c82-aac5-183947b6de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBert(nn.Module):\n",
    "    def __init__(self, model_path = None, num_labels = 6):\n",
    "        super().__init__()\n",
    "        if model_path == None:\n",
    "            self.bert = AutoModel.from_pretrained('bert-based-uncase')\n",
    "        else:\n",
    "            self.bert = AutoModel.from_pretrained(model_path)\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.lin = nn.Linear(768, num_labels)\n",
    "    def forward(self, ids, mask):\n",
    "        pooler = self.bert(ids, mask)[-1] # pooler \n",
    "        # import pdb; pdb.set_trace()\n",
    "        pooler = self.drop_out(pooler)\n",
    "        return self.lin(pooler)\n",
    "model = MyBert(model_path='./bert').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ef9b12d-0b2c-45dc-a240-5ef182b64a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=2e-5)\n",
    "loss_fn = F.binary_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bd0d2-2d75-49cf-9deb-4dd50e59d549",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "824bb90f-94b3-4c65-9557-b30bfb5a2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79c3aa1d-7666-46ae-9c3f-3b080e4b6bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ...: 100%|█| 500/500 [01:32<00:00,  5.41it/s, epoch=0, loss=tensor(0.13\n",
      "Training ...: 100%|█| 500/500 [01:34<00:00,  5.31it/s, epoch=1, loss=tensor(0.05\n",
      "Training ...: 100%|█| 500/500 [01:33<00:00,  5.33it/s, epoch=2, loss=tensor(0.04\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train(epochs = 1):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        tk0 = tqdm(train_dataloader, desc = 'Training ...')\n",
    "        losses = AverageMeter()\n",
    "        for i, batch in enumerate(tk0):\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            label = batch['label'].to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            output = model(ids, mask)\n",
    "            loss = loss_fn(output, label)\n",
    "            losses.update(loss, ids.shape[0])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            tk0.set_postfix(epoch = epoch, loss = losses.avg)\n",
    "train(3)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf97a2-c296-4386-b958-a4b3d2367cc1",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "487346a7-fd1c-4997-8edf-41702e28908e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.93\n",
      "F1 Score (Micro) = 0.7545219638242894\n",
      "F1 Score (Macro) = 0.39536461241887594\n",
      "CPU times: user 6.82 s, sys: 20.2 ms, total: 6.84 s\n",
      "Wall time: 6.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import metrics\n",
    "def eval():\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(val_dataloader, 0):\n",
    "            ids = data['input_ids'].to(DEVICE)\n",
    "            mask = data['attention_mask'].to(DEVICE)\n",
    "            \n",
    "            targets = data['label'].to(DEVICE, dtype = torch.float)\n",
    "            outputs = model(ids, mask)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets\n",
    "outputs, targets = eval()\n",
    "outputs = np.array(outputs) >= 0.5\n",
    "accuracy = metrics.accuracy_score(targets, outputs)\n",
    "f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "print(f\"Accuracy Score = {accuracy}\")\n",
    "print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "print(f\"F1 Score (Macro) = {f1_score_macro}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f605b-b57f-4ede-a155-68f34f5800cb",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e008870-854d-41a1-ad2f-983330f85527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_test_pred = []\n",
    "\n",
    "# def test(epoch):\n",
    "#     model.eval()\n",
    "    \n",
    "#     with torch.inference_mode():\n",
    "    \n",
    "#         for _, data in tqdm(enumerate(val_dataloader, 0)):\n",
    "\n",
    "#             ids = data['input_ids'].to(DEVICE)\n",
    "#             mask = data['attention_mask'].to(DEVICE)\n",
    "#             outputs = model(ids, mask)\n",
    "#             probas = torch.sigmoid(outputs)\n",
    "\n",
    "#             import pdb; pdb.set_trace()\n",
    "#             all_test_pred.append(probas)\n",
    "            \n",
    "#     return probas\n",
    "# probas = test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
