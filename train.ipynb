{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6d5797-3980-4590-a9f5-08d1a1c3c858",
   "metadata": {},
   "source": [
    "## Loading librarires and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f72f98ac-ec4d-4560-a755-959a4312c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import itertools\n",
    "import argparse\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa823451-8ef3-4267-8207-abed95e01864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fca68adf-5841-4bd8-87e5-617ab01828fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = './dataset/'\n",
    "df = pd.read_csv(data_dir+'processed_train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40040166-5f8f-47db-8584-3909ef11bc27",
   "metadata": {},
   "source": [
    "* use 2000 samples to make sure my code run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa674466-b18d-47fc-8e72-addc9b47f93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No, There is a larger opposition than that. Al...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Material to be included should be relevant, no...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is nothing a priori that prevents an adm...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Source\\nSource: .  (talk)</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\n\\nUser:Iblardi wrote: \"\"Yet in the above li...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text              labels\n",
       "0  No, There is a larger opposition than that. Al...  [0, 0, 0, 0, 0, 0]\n",
       "1  Material to be included should be relevant, no...  [0, 0, 0, 0, 0, 0]\n",
       "2  There is nothing a priori that prevents an adm...  [0, 0, 0, 0, 0, 0]\n",
       "3                          Source\\nSource: .  (talk)  [0, 0, 0, 0, 0, 0]\n",
       "4  \"\\n\\nUser:Iblardi wrote: \"\"Yet in the above li...  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = df.sample(2000).reset_index(drop=True)\n",
    "dfs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f1fad3b-b68b-4a7a-b7ee-00b5a81d4bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    object\n",
       "labels          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebdd9465-04fe-434d-8210-f9c9b49e2b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 0, 0, 0, 0, 0]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['labels'][0] \n",
    "# need to care about this\n",
    "# i need to use `ast.literal_eval` to convert to list below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a7ecb-030c-471a-983b-c77f9e0fe8cb",
   "metadata": {},
   "source": [
    "Split into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aa2a462-4f99-41f2-a192-b1c6eb68a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dfs.sample(frac=1, random_state=42)\n",
    "# val_df = dfs.drop(train_df.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2507b-99c5-4d25-a9d2-ff6a87092298",
   "metadata": {},
   "source": [
    "## Creating Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9abd679-a150-4530-97e6-642bf7c28cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d40ac05-b312-4956-888b-a3a45c1b7e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer: transformers.BertTokenizer, max_len = 128):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.text = self.df.comment_text.values\n",
    "        self.label = self.df.labels.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text[idx]\n",
    "        label = self.label[idx]\n",
    "\n",
    "        input = self.tokenizer.encode_plus(\n",
    "            text = text,\n",
    "            text_pair = None,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length = self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # import pdb; pdb.set_trace()\n",
    "        return {\n",
    "            'input_ids' : input.input_ids.squeeze(), ## MUST SQUEEZE\n",
    "            'attention_mask' : input.attention_mask.squeeze(), \n",
    "            'label' : torch.tensor(ast.literal_eval(self.label[idx]), dtype = torch.float)\n",
    "        }\n",
    "        # return {\n",
    "        #     'input_ids' : input.input_ids,\n",
    "        #     'attention_mask' : input.attention_mask\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11bfd869-adfc-4efe-9a5d-f652cbdb755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./bert')\n",
    "train = MyDataset(train_df, tokenizer, 200)\n",
    "# val = MyDataset(val_df, tokenizer, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24f2c511-a37a-424e-8cef-482c6c238b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=8, shuffle=True)\n",
    "# val_dataloader = DataLoader(val, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfbe5c-1594-4560-98c9-e0deddb71f5c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d72728e8-c7f3-4ace-bd7e-d397e195c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "049348d3-9a4c-4c82-aac5-183947b6de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBert(nn.Module):\n",
    "    def __init__(self, model_path = None, num_labels = 6):\n",
    "        super().__init__()\n",
    "        if model_path == None:\n",
    "            self.bert = AutoModel.from_pretrained('bert-based-uncase')\n",
    "        else:\n",
    "            self.bert = AutoModel.from_pretrained(model_path)\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.lin = nn.Linear(768, num_labels)\n",
    "    def forward(self, ids, mask):\n",
    "        pooler = self.bert(ids, mask)[-1] # pooler \n",
    "        # import pdb; pdb.set_trace()\n",
    "        pooler = self.drop_out(pooler)\n",
    "        return self.lin(pooler)\n",
    "model = MyBert(model_path='./bert').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ef9b12d-0b2c-45dc-a240-5ef182b64a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=3e-5)\n",
    "loss_fn = F.binary_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bd0d2-2d75-49cf-9deb-4dd50e59d549",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "824bb90f-94b3-4c65-9557-b30bfb5a2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79c3aa1d-7666-46ae-9c3f-3b080e4b6bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ...: 100%|█| 250/250 [00:45<00:00,  5.50it/s, epoch=0, loss=tensor(0.14\n",
      "Training ...: 100%|█| 250/250 [00:45<00:00,  5.48it/s, epoch=1, loss=tensor(0.06\n",
      "Training ...: 100%|█| 250/250 [00:46<00:00,  5.35it/s, epoch=2, loss=tensor(0.04\n",
      "Training ...: 100%|█| 250/250 [00:46<00:00,  5.33it/s, epoch=3, loss=tensor(0.03\n",
      "Training ...: 100%|█| 250/250 [00:47<00:00,  5.31it/s, epoch=4, loss=tensor(0.02\n"
     ]
    }
   ],
   "source": [
    "def train(epochs = 1):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        tk0 = tqdm(train_dataloader, desc = 'Training ...')\n",
    "        losses = AverageMeter()\n",
    "        for i, batch in enumerate(tk0):\n",
    "            ids = batch['input_ids'].to(DEVICE)\n",
    "            mask = batch['attention_mask'].to(DEVICE)\n",
    "            label = batch['label'].to(DEVICE)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            output = model(ids, mask)\n",
    "            loss = loss_fn(output, label)\n",
    "            losses.update(loss, ids.shape[0])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            tk0.set_postfix(epoch = epoch, loss = losses.avg)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            # break\n",
    "train(5)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f605b-b57f-4ede-a155-68f34f5800cb",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e008870-854d-41a1-ad2f-983330f85527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_test_pred = []\n",
    "\n",
    "# def test(epoch):\n",
    "#     model.eval()\n",
    "    \n",
    "#     with torch.inference_mode():\n",
    "    \n",
    "#         for _, data in tqdm(enumerate(val_dataloader, 0)):\n",
    "\n",
    "#             ids = data['input_ids'].to(DEVICE)\n",
    "#             mask = data['attention_mask'].to(DEVICE)\n",
    "#             outputs = model(ids, mask)\n",
    "#             probas = torch.sigmoid(outputs)\n",
    "\n",
    "#             import pdb; pdb.set_trace()\n",
    "#             all_test_pred.append(probas)\n",
    "            \n",
    "#     return probas\n",
    "# probas = test(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
